{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Advanced Time Series Forecasting with Uncertainty Quantification\n",
                "\n",
                "This notebook implements a Bayesian LSTM for multi-step time series forecasting with Monte Carlo Dropout for uncertainty quantification."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "import matplotlib.pyplot as plt\n",
                "from tensorflow.keras import layers, models, losses\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
                "import os\n",
                "\n",
                "# Set random seeds for reproducibility\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Generation (Data Factory)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DataFactory:\n",
                "    \"\"\"\n",
                "    A class to generate synthetic time series data and prepare it for \n",
                "    sequence-based models (LSTM/TCN).\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, seed=42):\n",
                "        np.random.seed(seed)\n",
                "        self.scaler = StandardScaler()\n",
                "\n",
                "    def generate_synthetic_data(self, n_points=1200, slope=0.01, seasonality_period=50, noise_level=0.1):\n",
                "        \"\"\"\n",
                "        Generates a synthetic time series with:\n",
                "        - Linear trend\n",
                "        - Seasonality (Sine wave)\n",
                "        - Heteroscedastic noise (noise level varies with value)\n",
                "        \"\"\"\n",
                "        time = np.arange(n_points)\n",
                "        \n",
                "        # Components\n",
                "        trend = slope * time\n",
                "        seasonality = np.sin(2 * np.pi * time / seasonality_period)\n",
                "        \n",
                "        # Heteroscedastic noise\n",
                "        signal = trend + seasonality\n",
                "        noise_amplitude = noise_level * (1 + 0.5 * np.abs(signal)) \n",
                "        noise = np.random.normal(0, noise_amplitude, size=n_points)\n",
                "        \n",
                "        data = signal + noise\n",
                "        \n",
                "        df = pd.DataFrame({'value': data, 'time': time})\n",
                "        return df\n",
                "\n",
                "    def create_sequences(self, data, lookback, horizon, step=1):\n",
                "        \"\"\"\n",
                "        Creates sliding window sequences for input (X) and target (y).\n",
                "        \"\"\"\n",
                "        X, y = [], []\n",
                "        if len(data.shape) == 1:\n",
                "            data = data.reshape(-1, 1)\n",
                "            \n",
                "        for i in range(0, len(data) - lookback - horizon + 1, step):\n",
                "            X.append(data[i : i + lookback])\n",
                "            # Predict point(s) at horizon\n",
                "            y.append(data[i + lookback : i + lookback + horizon])\n",
                "            \n",
                "        return np.array(X), np.array(y)\n",
                "\n",
                "    def split_data(self, df, train_ratio=0.7, val_ratio=0.15):\n",
                "        \"\"\"\n",
                "        Splits data into train, validation, and test sets respecting temporal order.\n",
                "        \"\"\"\n",
                "        n = len(df)\n",
                "        train_end = int(n * train_ratio)\n",
                "        val_end = int(n * (train_ratio + val_ratio))\n",
                "        \n",
                "        train_data = df.iloc[:train_end]\n",
                "        val_data = df.iloc[train_end:val_end]\n",
                "        test_data = df.iloc[val_end:]\n",
                "        \n",
                "        return train_data, val_data, test_data\n",
                "\n",
                "    def scale_data(self, train, val, test):\n",
                "        \"\"\"\n",
                "        Fits scaler on train, transforms train, val, test.\n",
                "        \"\"\"\n",
                "        train_scaled = self.scaler.fit_transform(train)\n",
                "        val_scaled = self.scaler.transform(val)\n",
                "        test_scaled = self.scaler.transform(test)\n",
                "        \n",
                "        return train_scaled, val_scaled, test_scaled"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Definition (Bayesian LSTM)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class BayesianLSTM(tf.keras.Model):\n",
                "    \"\"\"\n",
                "    LSTM model with MC Dropout for Uncertainty Quantification.\n",
                "    \"\"\"\n",
                "    def __init__(self, units, output_dim, dropout_rate=0.2):\n",
                "        super(BayesianLSTM, self).__init__()\n",
                "        self.dropout_rate = dropout_rate\n",
                "        \n",
                "        # LSTM Layers\n",
                "        self.lstm1 = layers.LSTM(units, return_sequences=True)\n",
                "        self.dropout1 = layers.Dropout(dropout_rate)\n",
                "        \n",
                "        self.lstm2 = layers.LSTM(units, return_sequences=True)\n",
                "        self.dropout2 = layers.Dropout(dropout_rate)\n",
                "        \n",
                "        self.lstm3 = layers.LSTM(units)\n",
                "        self.dropout3 = layers.Dropout(dropout_rate)\n",
                "        \n",
                "        self.dense = layers.Dense(output_dim)\n",
                "\n",
                "    def call(self, inputs, training=None):\n",
                "        \"\"\"\n",
                "        Forward pass.\n",
                "        Pass 'training' arg to dropouts to enable/disable MC sampling.\n",
                "        \"\"\"\n",
                "        x = self.lstm1(inputs)\n",
                "        x = self.dropout1(x, training=training)\n",
                "        \n",
                "        x = self.lstm2(x)\n",
                "        x = self.dropout2(x, training=training)\n",
                "        \n",
                "        x = self.lstm3(x)\n",
                "        x = self.dropout3(x, training=training)\n",
                "        \n",
                "        return self.dense(x)\n",
                "\n",
                "def quantile_loss(q, y, f):\n",
                "    e = (y - f)\n",
                "    return tf.maximum(q * e, (q - 1) * e)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Trainer:\n",
                "    def __init__(self, model, learning_rate=0.001, loss='mse'):\n",
                "        self.model = model\n",
                "        self.loss = loss \n",
                "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
                "        self.model.compile(optimizer=self.optimizer, loss=self.loss)\n",
                "\n",
                "    def train(self, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):\n",
                "        callbacks = [\n",
                "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
                "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1)\n",
                "        ]\n",
                "        \n",
                "        history = self.model.fit(\n",
                "            X_train, y_train,\n",
                "            validation_data=(X_val, y_val),\n",
                "            epochs=epochs,\n",
                "            batch_size=batch_size,\n",
                "            callbacks=callbacks,\n",
                "            verbose=1\n",
                "        )\n",
                "        return history"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation & Uncertainty"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class UncertaintyEvaluator:\n",
                "    def __init__(self, model, n_samples=100):\n",
                "        self.model = model\n",
                "        self.n_samples = n_samples\n",
                "\n",
                "    def predict_mc_dropout(self, X):\n",
                "        \"\"\"\n",
                "        Performs Monte Carlo Dropout prediction.\n",
                "        \"\"\"\n",
                "        predictions = []\n",
                "        for _ in range(self.n_samples):\n",
                "            # Force training=True to enable dropout during inference\n",
                "            pred = self.model(X, training=True)\n",
                "            predictions.append(pred)\n",
                "            \n",
                "        predictions = np.array(predictions) # Shape: (n_samples, n_data, output_dim)\n",
                "        \n",
                "        mean_pred = np.mean(predictions, axis=0)\n",
                "        lower_bound = np.percentile(predictions, 5, axis=0)\n",
                "        upper_bound = np.percentile(predictions, 95, axis=0)\n",
                "        \n",
                "        return mean_pred, lower_bound, upper_bound, predictions\n",
                "\n",
                "    def evaluate_metrics(self, y_true, y_pred, lower, upper):\n",
                "        \"\"\"\n",
                "        Calculates metrics. Handles squeezing dimensions and flattening.\n",
                "        \"\"\"\n",
                "        # Enforce flattening to avoid dimension mismatch (e.g. (N, 1) vs (N,))\n",
                "        y_true = np.array(y_true).flatten()\n",
                "        y_pred = np.array(y_pred).flatten()\n",
                "        lower = np.array(lower).flatten()\n",
                "        upper = np.array(upper).flatten()\n",
                "\n",
                "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
                "        mae = mean_absolute_error(y_true, y_pred)\n",
                "        \n",
                "        # PICP\n",
                "        captured = ((y_true >= lower) & (y_true <= upper))\n",
                "        picp = np.mean(captured)\n",
                "        \n",
                "        # MPIW\n",
                "        mpiw = np.mean(upper - lower)\n",
                "        \n",
                "        return {\n",
                "            \"RMSE\": rmse,\n",
                "            \"MAE\": mae,\n",
                "            \"PICP\": picp,\n",
                "            \"MPIW\": mpiw\n",
                "        }\n",
                "\n",
                "    def plot_results(self, time, y_true, y_pred, lower, upper, title=\"Forecast with Uncertainty\"):\n",
                "        plt.figure(figsize=(12, 6))\n",
                "        # Flatten inputs for plotting\n",
                "        plt.plot(time, y_true.flatten(), label='Ground Truth', color='black', alpha=0.7)\n",
                "        plt.plot(time, y_pred.flatten(), label='Prediction (Mean)', color='blue')\n",
                "        plt.fill_between(time, lower.flatten(), upper.flatten(), color='blue', alpha=0.2, label='90% Confidence Interval')\n",
                "        plt.title(title)\n",
                "        plt.legend()\n",
                "        plt.grid(True, alpha=0.3)\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Main Execution\n",
                "\n",
                "Here we run the pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parameters\n",
                "SEQ_LEN = 50   \n",
                "HORIZON = 1    \n",
                "EPOCHS = 10 # Adjust as needed\n",
                "BATCH_SIZE = 32\n",
                "DROPOUT_RATE = 0.2\n",
                "MC_SAMPLES = 100\n",
                "\n",
                "# 1. Data\n",
                "factory = DataFactory()\n",
                "df = factory.generate_synthetic_data(n_points=1500, slope=0.015, seasonality_period=60, noise_level=0.15)\n",
                "\n",
                "plt.figure(figsize=(10,4))\n",
                "plt.plot(df['time'], df['value'])\n",
                "plt.title(\"Synthetic Data\")\n",
                "plt.show()\n",
                "\n",
                "train_df, val_df, test_df = factory.split_data(df)\n",
                "train_scaled, val_scaled, test_scaled = factory.scale_data(train_df[['value']], val_df[['value']], test_df[['value']])\n",
                "\n",
                "X_train, y_train = factory.create_sequences(train_scaled, SEQ_LEN, HORIZON)\n",
                "X_val, y_val = factory.create_sequences(val_scaled, SEQ_LEN, HORIZON)\n",
                "X_test, y_test = factory.create_sequences(test_scaled, SEQ_LEN, HORIZON)\n",
                "\n",
                "# 2. Model\n",
                "model = BayesianLSTM(units=64, output_dim=1, dropout_rate=DROPOUT_RATE)\n",
                "# Build input shape\n",
                "model.build(input_shape=(None, SEQ_LEN, 1))\n",
                "model.summary()\n",
                "\n",
                "# 3. Train\n",
                "trainer = Trainer(model, learning_rate=0.001)\n",
                "history = trainer.train(X_train, y_train, X_val, y_val, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
                "\n",
                "plt.plot(history.history['loss'], label='Train')\n",
                "plt.plot(history.history['val_loss'], label='Val')\n",
                "plt.title(\"Loss Curves\")\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# 4. Evaluate\n",
                "evaluator = UncertaintyEvaluator(model, n_samples=MC_SAMPLES)\n",
                "print(\"Running MC Dropout inference...\")\n",
                "mean_pred, lower, upper, _ = evaluator.predict_mc_dropout(X_test)\n",
                "\n",
                "# Inverse transform helper\n",
                "def inverse(arr):\n",
                "    arr = np.array(arr)\n",
                "    # Handle 3D (samples, horizon, features)\n",
                "    if arr.ndim == 3:\n",
                "        orig_shape = arr.shape\n",
                "        arr_2d = arr.reshape(-1, arr.shape[-1])\n",
                "        inv_2d = factory.scaler.inverse_transform(arr_2d)\n",
                "        return inv_2d.reshape(orig_shape)\n",
                "    # Handle 1D (samples,)\n",
                "    if arr.ndim == 1:\n",
                "        return factory.scaler.inverse_transform(arr.reshape(-1, 1)).flatten()\n",
                "    # Handle 2D (samples, features)\n",
                "    return factory.scaler.inverse_transform(arr)\n",
                "\n",
                "y_test_inv = inverse(y_test)\n",
                "mean_pred_inv = inverse(mean_pred)\n",
                "lower_inv = inverse(lower)\n",
                "upper_inv = inverse(upper)\n",
                "\n",
                "metrics = evaluator.evaluate_metrics(y_test_inv, mean_pred_inv, lower_inv, upper_inv)\n",
                "print(\"Metrics:\", metrics)\n",
                "\n",
                "# Plot first 200 points\n",
                "time_axis = np.arange(len(y_test_inv))\n",
                "plot_len = min(200, len(y_test_inv))\n",
                "\n",
                "evaluator.plot_results(\n",
                "    time_axis[:plot_len], \n",
                "    y_test_inv[:plot_len], \n",
                "    mean_pred_inv[:plot_len], \n",
                "    lower_inv[:plot_len], \n",
                "    upper_inv[:plot_len]\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv312",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
